'use client'

import { useState, useRef, useEffect, useCallback } from 'react'
import { Mic, Square, Pause, Play, Edit2, Save, History, Trash2, FileText, Upload } from 'lucide-react'
import { Button } from '@/components/ui/button'
import { Input } from '@/components/ui/input'
import { toast } from 'sonner'
import TranscriptView, { type ManualNote } from './TranscriptView'
import AISummary from './AISummary'
import LanguageSelection from './LanguageSelection'
import type { Meeting, Transcript, SummaryProcess, LLMConfig } from '@/types/meeting'
import { getLanguagePreference, type TranscriptionLanguage } from '@/utils/transcription-language'
import { WAVRecorder } from '@/utils/wavEncoder'

export default function MeetingEmbedNew() {
  // ä¼šè®®çŠ¶æ€
  const [currentMeeting, setCurrentMeeting] = useState<Meeting | null>(null)
  const [transcripts, setTranscripts] = useState<Transcript[]>([])
  const [summary, setSummary] = useState<SummaryProcess | null>(null)
  const [manualNotes, setManualNotes] = useState<ManualNote[]>([])
  
  // å½•éŸ³çŠ¶æ€
  const [isRecording, setIsRecording] = useState(false)
  const [isPaused, setIsPaused] = useState(false)
  const [recordingTime, setRecordingTime] = useState(0)
  const [audioLevels, setAudioLevels] = useState<number[]>([])
  const [noteTitle, setNoteTitle] = useState('New Note')
  const [isEditingTitle, setIsEditingTitle] = useState(false)
  const [transcriptionLanguage, setTranscriptionLanguage] = useState<TranscriptionLanguage>('auto')
  const [isTranscribing, setIsTranscribing] = useState(false)
  const [isSilentDetected, setIsSilentDetected] = useState(false)
  const [isUploadingFile, setIsUploadingFile] = useState(false)
  const fileInputRef = useRef<HTMLInputElement>(null)
  
  // è§†å›¾çŠ¶æ€ï¼šfalse = å½•éŸ³é¡µé¢ï¼Œtrue = åŒæ å¸ƒå±€ï¼ˆåŸæ–‡+æ€»ç»“ï¼‰
  const [showSummaryView, setShowSummaryView] = useState(false)
  const [showHistory, setShowHistory] = useState(false)
  const [historyMeetings, setHistoryMeetings] = useState<Meeting[]>([])
  const [isLoadingHistory, setIsLoadingHistory] = useState(false)
  const [editingMeetingId, setEditingMeetingId] = useState<string | null>(null)
  const [editingTitle, setEditingTitle] = useState<string>('')
  
  // Refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const wavRecorderRef = useRef<WAVRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const streamRef = useRef<MediaStream | null>(null)
  const timerRef = useRef<NodeJS.Timeout | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const animationFrameRef = useRef<number | null>(null)
  const transcriptionIntervalRef = useRef<NodeJS.Timeout | null>(null)
  const lastTranscriptionTimeRef = useRef<number>(0) // ä¸Šæ¬¡è½¬å½•çš„æ—¶é—´ç‚¹
  const transcriptionChunksRef = useRef<Blob[]>([]) // ç”¨äºå®æ—¶è½¬å½•çš„éŸ³é¢‘ç‰‡æ®µï¼ˆæ»‘åŠ¨çª—å£ï¼Œä¿å­˜æœ€è¿‘8ç§’ï¼‰
  const transcriptionWindowRef = useRef<Blob[]>([]) // æ»‘åŠ¨çª—å£ç¼“å†²åŒºï¼ˆä¿å­˜æœ€è¿‘8ç§’çš„éŸ³é¢‘ï¼‰
  const lastProcessedTimeRef = useRef<number>(0) // ä¸Šæ¬¡å¤„ç†çš„æ—¶é—´ç‚¹ï¼ˆç”¨äºå¢é‡è¯†åˆ«ï¼‰
  const recordingTimeRef = useRef<number>(0) // å½•éŸ³æ—¶é—´çš„ refï¼ˆç”¨äºåœ¨å®šæ—¶å™¨ä¸­è®¿é—®æœ€æ–°å€¼ï¼‰
  const isRecordingRef = useRef<boolean>(false) // ç”¨äºåœ¨å®šæ—¶å™¨ä¸­è®¿é—®æœ€æ–°çŠ¶æ€
  const currentMeetingIdRef = useRef<string | null>(null) // ä¼šè®®IDçš„ refï¼ˆç”¨äºåœ¨å®šæ—¶å™¨ä¸­è®¿é—®æœ€æ–°å€¼ï¼‰
  const isPausedRef = useRef<boolean>(false) // ç”¨äºåœ¨å®šæ—¶å™¨ä¸­è®¿é—®æœ€æ–°çŠ¶æ€
  const transcriptionLanguageRef = useRef<TranscriptionLanguage>('auto') // ç”¨äºåœ¨å®šæ—¶å™¨ä¸­è®¿é—®æœ€æ–°è¯­è¨€è®¾ç½®
  const previousWindowTextRef = useRef<string>('') // å‰ä¸€ä¸ªçª—å£çš„å®Œæ•´æ–‡æœ¬ï¼ˆç”¨äºLCPå¢é‡æå–ï¼‰

  // æ ¼å¼åŒ–æ—¶é—´
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  // æ ¼å¼åŒ–æ—¶é—´æˆ³
  const formatTimestamp = (seconds: number) => {
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    return `[${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}]`
  }

  // è®¡ç®—æœ€é•¿å…¬å…±å‰ç¼€ï¼ˆLCPï¼‰ç”¨äºå¢é‡æ–‡æœ¬æå–
  const longestCommonPrefix = (str1: string, str2: string): string => {
    if (!str1 || !str2) return ''
    
    let i = 0
    const minLength = Math.min(str1.length, str2.length)
    
    // é€å­—ç¬¦æ¯”è¾ƒï¼Œæ‰¾åˆ°æœ€é•¿å…¬å…±å‰ç¼€
    while (i < minLength && str1[i] === str2[i]) {
      i++
    }
    
    // ä¸ºäº†æ›´å‡†ç¡®åœ°åŒ¹é…ï¼Œå°è¯•åœ¨è¯è¾¹ç•Œå¤„æˆªæ–­
    // è¿™æ ·å¯ä»¥é¿å…åœ¨è¯ä¸­é—´æˆªæ–­
    let prefix = str1.substring(0, i)
    
    // å¦‚æœå‰ç¼€ä¸æ˜¯ä»¥ç©ºæ ¼æˆ–æ ‡ç‚¹ç»“å°¾ï¼Œå°è¯•æ‰¾åˆ°æœ€è¿‘çš„è¯è¾¹ç•Œ
    if (i < minLength && prefix.length > 0) {
      const lastSpaceIndex = prefix.lastIndexOf(' ')
      const lastPunctuationIndex = Math.max(
        prefix.lastIndexOf('ã€‚'),
        prefix.lastIndexOf('ï¼Œ'),
        prefix.lastIndexOf('ã€'),
        prefix.lastIndexOf('ï¼'),
        prefix.lastIndexOf('ï¼Ÿ'),
        prefix.lastIndexOf('.'),
        prefix.lastIndexOf(','),
        prefix.lastIndexOf('!'),
        prefix.lastIndexOf('?')
      )
      const boundaryIndex = Math.max(lastSpaceIndex, lastPunctuationIndex)
      
      if (boundaryIndex > prefix.length * 0.5) {
        // å¦‚æœè¯è¾¹ç•Œåœ¨ä¸­é—´ä½ç½®ä¹‹åï¼Œä½¿ç”¨è¯è¾¹ç•Œ
        prefix = prefix.substring(0, boundaryIndex + 1)
      }
    }
    
    return prefix
  }

  // åˆ›å»ºæ–°ä¼šè®®
  const createMeeting = async (title: string) => {
    try {
      const response = await fetch('/api/meetings', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ title })
      })
      
      if (!response.ok) throw new Error('Failed to create meeting')
      
      const { meeting } = await response.json()
      setCurrentMeeting(meeting)
      return meeting
    } catch (error: any) {
      console.error('Error creating meeting:', error)
      toast.error(error.message || 'Failed to create meeting')
      return null
    }
  }

  // åŠ è½½ä¼šè®®æ•°æ®
  const loadMeetingData = async (meetingId: string) => {
    try {
      // åŠ è½½è½¬å½•
      const transcriptsRes = await fetch(`/api/meetings/${meetingId}/transcripts`)
      if (transcriptsRes.ok) {
        const { transcripts: ts } = await transcriptsRes.json()
        setTranscripts(ts || [])
      }

      // åŠ è½½æ‘˜è¦ï¼ˆé»˜è®¤åŠ è½½ standard æ¨¡æ¿ï¼‰
      const summaryRes = await fetch(`/api/meetings/${meetingId}/summary?template_id=standard`)
      if (summaryRes.ok) {
        const { summary: s } = await summaryRes.json()
        setSummary(s)
      }
    } catch (error) {
      console.error('Error loading meeting data:', error)
    }
  }

  // åŠ è½½å†å²ä¼šè®®åˆ—è¡¨
  const loadHistoryMeetings = useCallback(async () => {
    setIsLoadingHistory(true)
    try {
      const response = await fetch('/api/meetings')
      if (response.ok) {
        const { meetings } = await response.json()
        // åªæ˜¾ç¤ºå·²å®Œæˆçš„ä¼šè®®
        const completedMeetings = (meetings || []).filter(
          (m: Meeting) => m.status === 'completed'
        )
        setHistoryMeetings(completedMeetings)
      } else {
        console.error('Failed to load history meetings')
        setHistoryMeetings([])
      }
    } catch (error) {
      console.error('Error loading history meetings:', error)
      setHistoryMeetings([])
    } finally {
      setIsLoadingHistory(false)
    }
  }, [])

  // åŠ è½½æŒ‡å®šä¼šè®®
  const loadMeeting = useCallback(async (meetingId: string) => {
    try {
      const response = await fetch(`/api/meetings/${meetingId}`)
      if (response.ok) {
        const { meeting } = await response.json()
        setCurrentMeeting(meeting)
        setNoteTitle(meeting.title)
        await loadMeetingData(meetingId)
        setShowHistory(false)
        setShowSummaryView(true)
        // é€šçŸ¥sidebarå…³é—­å†å²è§†å›¾
        window.dispatchEvent(new CustomEvent('meeting-history-toggle', {
          detail: { show: false }
        }))
        toast.success('Meeting loaded')
      } else {
        toast.error('Failed to load meeting')
      }
    } catch (error) {
      console.error('Error loading meeting:', error)
      toast.error('Failed to load meeting')
    }
  }, [])

  // åˆ é™¤ä¼šè®®
  const deleteMeeting = useCallback(async (meetingId: string, event: React.MouseEvent) => {
    event.stopPropagation() // é˜»æ­¢è§¦å‘å¡ç‰‡ç‚¹å‡»äº‹ä»¶
    
    if (!confirm('Are you sure you want to delete this meeting? This action cannot be undone.')) {
      return
    }

    try {
      const response = await fetch(`/api/meetings/${meetingId}`, {
        method: 'DELETE',
      })

      if (response.ok) {
        toast.success('Meeting deleted')
        // ä»åˆ—è¡¨ä¸­ç§»é™¤
        setHistoryMeetings(prev => prev.filter(m => m.id !== meetingId))
        // å¦‚æœå½“å‰æ­£åœ¨æŸ¥çœ‹è¿™ä¸ªä¼šè®®ï¼Œé‡ç½®çŠ¶æ€
        if (currentMeeting?.id === meetingId) {
          setCurrentMeeting(null)
          setShowSummaryView(false)
          setTranscripts([])
          setSummary(null)
        }
      } else {
        toast.error('Failed to delete meeting')
      }
    } catch (error) {
      console.error('Error deleting meeting:', error)
      toast.error('Failed to delete meeting')
    }
  }, [currentMeeting])

  // å¼€å§‹ç¼–è¾‘ä¼šè®®æ ‡é¢˜
  const startEditingTitle = useCallback((meeting: Meeting, event: React.MouseEvent) => {
    event.stopPropagation() // é˜»æ­¢è§¦å‘å¡ç‰‡ç‚¹å‡»äº‹ä»¶
    setEditingMeetingId(meeting.id)
    setEditingTitle(meeting.title)
  }, [])

  // ä¿å­˜ä¼šè®®æ ‡é¢˜
  const saveMeetingTitle = useCallback(async (meetingId: string, event?: React.MouseEvent | React.KeyboardEvent) => {
    if (event) {
      event.stopPropagation()
    }

    if (!editingTitle.trim()) {
      toast.error('Title cannot be empty')
      return
    }

    try {
      const response = await fetch(`/api/meetings/${meetingId}`, {
        method: 'PATCH',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ title: editingTitle.trim() })
      })

      if (response.ok) {
        const { meeting } = await response.json()
        // æ›´æ–°åˆ—è¡¨ä¸­çš„ä¼šè®®æ ‡é¢˜
        setHistoryMeetings(prev => 
          prev.map(m => m.id === meetingId ? meeting : m)
        )
        // å¦‚æœå½“å‰æ­£åœ¨æŸ¥çœ‹è¿™ä¸ªä¼šè®®ï¼Œä¹Ÿæ›´æ–°æ ‡é¢˜
        if (currentMeeting?.id === meetingId) {
          setCurrentMeeting(meeting)
          setNoteTitle(meeting.title)
        }
        setEditingMeetingId(null)
        setEditingTitle('')
        toast.success('Title updated')
      } else {
        toast.error('Failed to update title')
      }
    } catch (error) {
      console.error('Error updating title:', error)
      toast.error('Failed to update title')
    }
  }, [editingTitle, currentMeeting])

  // å–æ¶ˆç¼–è¾‘
  const cancelEditing = useCallback((event?: React.MouseEvent | React.KeyboardEvent) => {
    if (event) {
      event.stopPropagation()
    }
    setEditingMeetingId(null)
    setEditingTitle('')
  }, [])

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    try {
      // å¦‚æœæ²¡æœ‰ä¼šè®®ï¼Œå…ˆåˆ›å»ºä¸€ä¸ª
      let meetingToUse = currentMeeting
      if (!meetingToUse) {
        const meeting = await createMeeting(noteTitle)
        if (!meeting) return
        setCurrentMeeting(meeting)
        currentMeetingIdRef.current = meeting.id // åŒæ­¥æ›´æ–° ref
        meetingToUse = meeting
      } else {
        currentMeetingIdRef.current = meetingToUse.id // åŒæ­¥æ›´æ–° ref
      }

      // è¯·æ±‚éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      streamRef.current = stream

      // ä½¿ç”¨ WAV å½•éŸ³å™¨ï¼ˆwhisper.cpp åŸç”Ÿæ”¯æŒï¼‰
      console.log('ğŸ™ï¸ ä½¿ç”¨ WAV æ ¼å¼å½•éŸ³ï¼ˆ16kHz, å•å£°é“, whisper.cpp åŸç”Ÿæ”¯æŒï¼‰')
      
      const wavRecorder = new WAVRecorder(16000) // 16kHz é‡‡æ ·ç‡ï¼ˆWhisper æ¨èï¼‰
      await wavRecorder.start(stream)
      wavRecorderRef.current = wavRecorder
      
      // ä»ç„¶åˆ›å»º MediaRecorder ç”¨äºéŸ³é¢‘å¯è§†åŒ–ï¼ˆä½†ä¸ç”¨äºå½•éŸ³ï¼‰
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })
      mediaRecorderRef.current = mediaRecorder
      audioChunksRef.current = []

      // è®¾ç½®éŸ³é¢‘åˆ†æå™¨
      const audioContext = new AudioContext()
      const analyser = audioContext.createAnalyser()
      const source = audioContext.createMediaStreamSource(stream)
      source.connect(analyser)
      analyser.fftSize = 256
      
      audioContextRef.current = audioContext
      analyserRef.current = analyser

      // åˆ†æéŸ³é¢‘çº§åˆ«
      const analyzeAudio = () => {
        if (!analyserRef.current) return
        
        const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)
        analyserRef.current.getByteFrequencyData(dataArray)
        
        const bars = 12
        const step = Math.floor(dataArray.length / bars)
        const levels: number[] = []
        
        for (let i = 0; i < bars; i++) {
          const index = i * step
          const value = dataArray[index] / 255
          levels.push(Math.max(0.1, value))
        }
        
        setAudioLevels(levels)
        animationFrameRef.current = requestAnimationFrame(analyzeAudio)
      }
      analyzeAudio()

      // å¤„ç†å½•éŸ³æ•°æ®
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
          // ä¿å­˜åˆ°æ»‘åŠ¨çª—å£ç¼“å†²åŒºï¼ˆç”¨äºé‡å è¯†åˆ«ï¼‰
          transcriptionWindowRef.current.push(event.data)
          
          // é™åˆ¶æ»‘åŠ¨çª—å£å¤§å°ä¸ºçº¦9ç§’ï¼ˆchunk = 3ç§’ï¼Œä¿ç•™æœ€è¿‘3ä¸ªï¼‰
          // 9ç§’çª—å£å¯ä»¥ç¡®ä¿ Whisper æœ‰è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡æ¥è¯†åˆ«ä¸­æ–‡
          // chunk 3ç§’ + çª—å£9ç§’ = 3ä¸ªchunkï¼Œè¿™æ ·æ¯æ¬¡å‘é€çš„éŸ³é¢‘æ›´ç¨³å®š
          const maxWindowChunks = 3 // çº¦9ç§’çš„éŸ³é¢‘ï¼ˆ3ä¸ª3ç§’chunkï¼‰
          if (transcriptionWindowRef.current.length > maxWindowChunks) {
            transcriptionWindowRef.current.shift() // ç§»é™¤æœ€æ—§çš„chunk
          }
          
          console.log('ğŸµ éŸ³é¢‘æ•°æ®å·²æ·»åŠ åˆ°æ»‘åŠ¨çª—å£:', {
            chunkSize: `${(event.data.size / 1024).toFixed(2)} KB`,
            windowSize: transcriptionWindowRef.current.length,
            totalSize: `${(transcriptionWindowRef.current.reduce((sum, chunk) => sum + chunk.size, 0) / 1024).toFixed(2)} KB`
          })
        }
      }

      // å¼€å§‹å½•éŸ³
      // chunk æ—¶é•¿æ”¹ä¸º 3 ç§’ï¼Œç¡®ä¿ Whisper æœ‰è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡è¯†åˆ«ä¸­æ–‡
      // 2 ç§’çš„ chunk ä»ç„¶å¯èƒ½å¤ªçŸ­ï¼Œå¯¼è‡´åç»­å†…å®¹æ— æ³•è¯†åˆ«
      // 3 ç§’çš„ chunk å¯ä»¥æä¾›æ›´ç¨³å®šçš„è¯†åˆ«ç»“æœ
      mediaRecorder.start(3000) // æ¯3ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®
      setIsRecording(true)
      setIsPaused(false)
      isRecordingRef.current = true
      isPausedRef.current = false
      setRecordingTime(0)
      recordingTimeRef.current = 0 // é‡ç½®å½•éŸ³æ—¶é—´ ref
      setShowSummaryView(false) // å½•éŸ³æ—¶æ˜¾ç¤ºå½•éŸ³é¡µé¢
      setTranscripts([]) // é‡ç½®è½¬å½•åˆ—è¡¨
      setIsSilentDetected(false) // é‡ç½®é™éŸ³æ£€æµ‹çŠ¶æ€
      setSummary(null) // æ¸…é™¤æ—§çš„æ‘˜è¦
      lastTranscriptionTimeRef.current = 0 // é‡ç½®è½¬å½•æ—¶é—´

      // å¼€å§‹è®¡æ—¶
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => {
          const newTime = prev + 1
          recordingTimeRef.current = newTime // åŒæ­¥æ›´æ–° ref
          return newTime
        })
      }, 1000)

      // å®æ—¶è½¬å½•å·²ç¦ç”¨ - åªåœ¨å½•éŸ³ç»“æŸåè¿›è¡Œå®Œæ•´è½¬å½•
      // ä¿ç•™ç›¸å…³ ref çš„åˆå§‹åŒ–ä»¥ä¾›å½•éŸ³ç»“æŸåçš„è½¬å½•ä½¿ç”¨
      lastTranscriptionTimeRef.current = 0
      lastProcessedTimeRef.current = 0
      transcriptionWindowRef.current = []
      previousWindowTextRef.current = ''
      isRecordingRef.current = true
      isPausedRef.current = false
      
      console.log('ğŸ™ï¸ å½•éŸ³å¼€å§‹ï¼Œä¼šè®®ID:', meetingToUse?.id, '(å®æ—¶è½¬å½•å·²ç¦ç”¨)')

      // æ¸…ç†è½¬å½•å®šæ—¶å™¨
      mediaRecorder.onstop = async () => {
        isRecordingRef.current = false
        if (transcriptionIntervalRef.current) {
          clearInterval(transcriptionIntervalRef.current)
          transcriptionIntervalRef.current = null
        }
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current)
        }
        if (audioContextRef.current) {
          await audioContextRef.current.close()
        }
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => track.stop())
        }
        setAudioLevels([])
        
        // è½¬å½•æœ€åå‰©ä½™çš„éŸ³é¢‘ç‰‡æ®µï¼ˆæ»‘åŠ¨çª—å£ä¸­çš„å†…å®¹ï¼‰
        const finalMeetingId = currentMeetingIdRef.current
        if (transcriptionWindowRef.current.length > 0 && finalMeetingId) {
          try {
            const audioBlob = new Blob(transcriptionWindowRef.current, { type: 'audio/webm' })
            const windowStartTime = Math.max(0, recordingTimeRef.current - 9)
            const formData = new FormData()
            formData.append('audio', audioBlob, 'recording-segment.webm')
            formData.append('startTime', windowStartTime.toString())
            formData.append('windowStartTime', windowStartTime.toString())
            formData.append('lastProcessedTime', lastProcessedTimeRef.current.toString())
            formData.append('language', transcriptionLanguageRef.current)
            
            const response = await fetch(`/api/meetings/${finalMeetingId}/transcribe-live`, {
              method: 'POST',
              body: formData,
            })
            
            if (response.ok) {
              const data = await response.json()
              const newTranscripts = data.transcripts || []
              const message = data.message || ''
              
              // å¦‚æœæ˜¯é™éŸ³æ£€æµ‹ï¼Œè·³è¿‡å¤„ç†
              if (message === 'no recording detected') {
                console.log('ğŸ”‡ æœ€ç»ˆè½¬å½•ï¼šæ£€æµ‹åˆ°é™éŸ³ç‰‡æ®µï¼Œè·³è¿‡')
                return
              }
              
              if (newTranscripts && newTranscripts.length > 0) {
                setTranscripts(prev => {
                  const result = [...prev]
                  
                  for (const newTranscript of newTranscripts) {
                    // åªå¤„ç†ä¸Šæ¬¡å¤„ç†æ—¶é—´ä¹‹åçš„æ–°è½¬å½•
                    if (newTranscript.audio_start_time <= lastProcessedTimeRef.current) {
                      continue
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´é‡å çš„å·²æœ‰è½¬å½•
                    const hasOverlap = result.some(existing => {
                      const timeOverlap = Math.abs(existing.audio_start_time - newTranscript.audio_start_time) < 1.0
                      const textSimilar = existing.transcript === newTranscript.transcript ||
                                        existing.transcript.includes(newTranscript.transcript) ||
                                        newTranscript.transcript.includes(existing.transcript)
                      return timeOverlap && textSimilar
                    })
                    
                    if (!hasOverlap) {
                      result.push(newTranscript)
                    }
                  }
                  
                  // æŒ‰æ—¶é—´æ’åº
                  result.sort((a, b) => a.audio_start_time - b.audio_start_time)
                  
                  return result
                })
              }
            }
          } catch (error) {
            console.error('Final transcription error:', error)
          }
        }
        
        transcriptionChunksRef.current = []
      }

      toast.success('Recording started')
    } catch (error) {
      console.error('Failed to start recording:', error)
      toast.error('Failed to access microphone. Please check permissions.')
      setIsRecording(false)
    }
  }, [currentMeeting, noteTitle])

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(async () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
      setIsPaused(false)
      isRecordingRef.current = false
      isPausedRef.current = false

      if (timerRef.current) {
        clearInterval(timerRef.current)
        timerRef.current = null
      }

      // åœæ­¢ WAV å½•éŸ³å™¨å¹¶è·å– WAV æ•°æ®
      const audioBlob = wavRecorderRef.current?.stop() || new Blob([], { type: 'audio/wav' })
      
      console.log('âœ… WAV å½•éŸ³å®Œæˆ:', {
        size: `${(audioBlob.size / 1024 / 1024).toFixed(2)} MB`,
        type: audioBlob.type,
        duration: `${recordingTime}s`
      })
      
      // è‡ªåŠ¨ä¿å­˜å½•éŸ³æ–‡ä»¶åˆ°æœ¬åœ°
      if (audioBlob.size > 0) {
        try {
          // ç”Ÿæˆæ–‡ä»¶åï¼šä¼šè®®æ ‡é¢˜_æ—¶é—´æˆ³.wav
          const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5) // æ ¼å¼ï¼š2024-01-01T12-00-00
          const safeTitle = (noteTitle || 'Recording').replace(/[^a-z0-9]/gi, '_').replace(/_+/g, '_').slice(0, 50) // æ¸…ç†æ ‡é¢˜ï¼Œé™åˆ¶é•¿åº¦
          const fileName = `${safeTitle}_${timestamp}.wav`
          
          // åˆ›å»ºä¸‹è½½é“¾æ¥
          const url = URL.createObjectURL(audioBlob)
          const link = document.createElement('a')
          link.href = url
          link.download = fileName
          link.style.display = 'none'
          document.body.appendChild(link)
          
          // è§¦å‘ä¸‹è½½
          link.click()
          
          // æ¸…ç†
          setTimeout(() => {
            document.body.removeChild(link)
            URL.revokeObjectURL(url)
          }, 100)
          
          console.log('ğŸ’¾ å½•éŸ³æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°:', fileName)
          toast.success(`Recording saved as ${fileName}`)
        } catch (saveError: any) {
          console.error('âŒ ä¿å­˜å½•éŸ³æ–‡ä»¶å¤±è´¥:', saveError)
          toast.error('Failed to save recording file')
        }
      }
      
      if (!currentMeeting) {
        toast.error('No meeting found')
        return
      }

      toast.success('Recording stopped. Processing transcription...')
      setIsTranscribing(true) // è®¾ç½®è½¬å½•çŠ¶æ€
      
      try {
        // åˆ¤æ–­æ˜¯å¦éœ€è¦ä¸Šä¼ åˆ° Blob Storageï¼ˆå¤§äº 4MBï¼‰
        const MAX_INLINE_AUDIO_SIZE_MB = 4
        const audioSizeMB = audioBlob.size / (1024 * 1024)
        
        // åˆ›å»ºç›´æ¥ä¸Šä¼ çš„ FormData è¾…åŠ©å‡½æ•°
        const createDirectUploadFormData = (): FormData => {
          const formData = new FormData()
          formData.append('audio', audioBlob, 'recording.wav')
          formData.append('language', transcriptionLanguage)
          formData.append('audioDuration', recordingTime.toString())
          return formData
        }
        
        let audioPayload: FormData | { audioUrl: string; audioDuration: string; language: string }

        if (audioSizeMB > MAX_INLINE_AUDIO_SIZE_MB) {
          console.log(`ğŸ“¤ Recording size (${audioSizeMB.toFixed(2)} MB) exceeds ${MAX_INLINE_AUDIO_SIZE_MB} MB, uploading to Blob Storage...`)
          const uploadFormData = new FormData()
          uploadFormData.append('file', audioBlob, 'recording.wav')
          
          try {
            const uploadResponse = await fetch('/api/upload', {
              method: 'POST',
              body: uploadFormData,
            })
            
            if (uploadResponse.ok) {
              const uploadData = await uploadResponse.json()
              
              // æ£€æŸ¥å“åº”æ ¼å¼
              if (uploadData.url && !uploadData.url.startsWith('data:')) {
                // æˆåŠŸä¸Šä¼ åˆ° Blob Storageï¼ˆä¸æ˜¯ base64 data URLï¼‰
                audioPayload = {
                  audioUrl: uploadData.url,
                  audioDuration: recordingTime.toString(),
                  language: transcriptionLanguage
                }
                console.log('âœ… Recording uploaded to Blob Storage:', uploadData.url)
              } else {
                // base64 data URLï¼ˆBlob Storage æœªé…ç½®ï¼‰ï¼Œå›é€€åˆ°ç›´æ¥ä¸Šä¼ 
                console.warn('âš ï¸ Blob Storage not configured. File too large for direct upload.')
                toast.error('Recording too large. Please configure Blob Storage or reduce recording length.')
                setIsTranscribing(false)
                return
              }
            } else {
              // ä¸Šä¼ å¤±è´¥
              const errorData = await uploadResponse.json().catch(() => ({}))
              console.error('âŒ Blob Storage upload failed:', errorData.error || uploadResponse.statusText)
              toast.error('Failed to upload large recording. Please try a shorter recording.')
              setIsTranscribing(false)
              return
            }
          } catch (uploadError: any) {
            // ä¸Šä¼ å¼‚å¸¸
            console.error('âŒ Blob Storage upload error:', uploadError.message)
            toast.error('Failed to upload recording. Please try again.')
            setIsTranscribing(false)
            return
          }
        } else {
          // æ–‡ä»¶å°äºç­‰äº 4MBï¼Œç›´æ¥ä¸Šä¼ 
          console.log(`ğŸ“¤ Recording size (${audioSizeMB.toFixed(2)} MB) is within limit, sending directly.`)
          audioPayload = createDirectUploadFormData()
        }

        // è°ƒç”¨è½¬å½• API
        const response = await fetch(`/api/meetings/${currentMeeting.id}/transcribe`, {
          method: 'POST',
          body: audioPayload instanceof FormData ? audioPayload : JSON.stringify(audioPayload),
          headers: audioPayload instanceof FormData ? {} : { 'Content-Type': 'application/json' },
        })
        
        if (response.ok) {
          const data = await response.json()
          const newTranscripts = data.transcripts || []
          const message = data.message || ''
          
          // æ£€æŸ¥æ˜¯å¦ä¸ºé™éŸ³æ£€æµ‹
          if (message === 'no recording detected') {
            setIsSilentDetected(true)
            toast.warning('No recording detected - audio appears to be silent')
            // é™éŸ³æ—¶ä¸è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
            setSummary(null)
            setShowSummaryView(true)
            return
          } else {
            setIsSilentDetected(false)
          }
          
          if (newTranscripts.length > 0) {
            setTranscripts(prev => [...prev, ...newTranscripts])
          }
          
          // æ›´æ–°ä¼šè®®çŠ¶æ€
          const updateResponse = await fetch(`/api/meetings/${currentMeeting.id}`, {
            method: 'PATCH',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
              status: 'completed',
              audio_duration: recordingTime 
            })
          })
          
          if (updateResponse.ok) {
            const { meeting: updatedMeeting } = await updateResponse.json()
            setCurrentMeeting(updatedMeeting)
            // å¦‚æœæ­£åœ¨æ˜¾ç¤ºå†å²è§†å›¾ï¼Œåˆ·æ–°å†å²åˆ—è¡¨
            if (showHistory) {
              loadHistoryMeetings()
            }
          }
          
          if (newTranscripts.length > 0) {
            toast.success('Transcription completed')
            
            // åœæ­¢å½•åˆ¶ååˆ‡æ¢åˆ°åŒæ å¸ƒå±€
            setSummary(null) // æ¸…é™¤æ—§çš„æ‘˜è¦ï¼ˆæ–°å½•éŸ³è¿˜æ²¡æœ‰ç”Ÿæˆæ‘˜è¦ï¼‰
            setShowSummaryView(true)

            // åªæœ‰åœ¨æœ‰è½¬å½•æ–‡æœ¬æ—¶æ‰è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
            // è‡ªåŠ¨ç”Ÿæˆä¸€æ¬¡é»˜è®¤çš„ä¼šè®®æ€»ç»“ï¼šä½¿ç”¨ 'default' æ¨¡æ¿ï¼ˆä¸ä½¿ç”¨ä»»ä½•è‡ªå®šä¹‰æ¨¡æ¿ï¼‰ï¼Œé»˜è®¤è‹±æ–‡
            try {
              await handleGenerateSummary('default', undefined, 'en', false)
            } catch (e) {
              console.error('Auto-generate summary failed:', e)
            }
          } else {
            toast.warning('Transcription completed but no text was extracted')
            // æ²¡æœ‰è½¬å½•æ–‡æœ¬æ—¶ï¼Œä¸è°ƒç”¨ LLM
            setSummary(null)
            setShowSummaryView(true)
          }
        } else {
          // å°è¯•è§£æé”™è¯¯ä¿¡æ¯
          let errorMessage = 'Transcription failed'
          try {
            const errorData = await response.json()
            errorMessage = errorData.error || errorData.details || errorData.message || errorMessage
            console.error('Transcription API error:', {
              status: response.status,
              statusText: response.statusText,
              error: errorData
            })
          } catch (parseError) {
            console.error('Failed to parse error response:', parseError)
            errorMessage = `Transcription failed (HTTP ${response.status})`
          }
          
          toast.error(errorMessage)
          console.error('Transcription failed:', errorMessage)
          
          // å³ä½¿è½¬å½•å¤±è´¥ï¼Œä¹Ÿåˆ‡æ¢åˆ°åŒæ å¸ƒå±€ï¼Œå…è®¸ç”¨æˆ·æŸ¥çœ‹å·²æœ‰çš„è½¬å½•
          setSummary(null) // æ¸…é™¤æ—§çš„æ‘˜è¦
          setShowSummaryView(true)
        }
      } catch (error: any) {
        console.error('Transcription error:', error)
        const errorMessage = error.message || 'Transcription service unavailable'
        toast.error(errorMessage)
        // å³ä½¿è½¬å½•å¤±è´¥ï¼Œä¹Ÿåˆ‡æ¢åˆ°åŒæ å¸ƒå±€
        setSummary(null) // æ¸…é™¤æ—§çš„æ‘˜è¦
        setShowSummaryView(true)
      } finally {
        setIsTranscribing(false) // æ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼Œéƒ½æ¸…é™¤è½¬å½•çŠ¶æ€
      }
    }
  }, [isRecording, recordingTime, currentMeeting, showHistory, loadHistoryMeetings])

  // æš‚åœ/æ¢å¤å½•éŸ³
  const togglePause = useCallback(() => {
    if (!mediaRecorderRef.current) return

    if (isPaused) {
      mediaRecorderRef.current.resume()
      setIsPaused(false)
      isPausedRef.current = false
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)
      toast.info('Recording resumed')
    } else {
      mediaRecorderRef.current.pause()
      setIsPaused(true)
      isPausedRef.current = true
      if (timerRef.current) {
        clearInterval(timerRef.current)
      }
      // æš‚åœæ—¶ä¹Ÿæš‚åœè½¬å½•å®šæ—¶å™¨ï¼ˆé€šè¿‡isPausedæ£€æŸ¥ï¼‰
      toast.info('Recording paused')
    }
  }, [isPaused])

  // å¤„ç†æ–‡ä»¶ä¸Šä¼ 
  const handleFileUpload = useCallback(async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0]
    if (!file) return

    // éªŒè¯æ–‡ä»¶ç±»å‹
    const validAudioTypes = ['audio/wav', 'audio/mpeg', 'audio/mp3', 'audio/webm', 'audio/ogg', 'audio/m4a', 'audio/aac']
    const isValidType = validAudioTypes.includes(file.type) || 
                       /\.(wav|mp3|m4a|ogg|webm|aac)$/i.test(file.name)
    
    if (!isValidType) {
      toast.error('Please select a valid audio file (WAV, MP3, M4A, OGG, WEBM, AAC)')
      return
    }

    // éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆæœ€å¤§ 100MBï¼‰
    const MAX_FILE_SIZE = 100 * 1024 * 1024 // 100MB
    if (file.size > MAX_FILE_SIZE) {
      toast.error(`File size exceeds ${MAX_FILE_SIZE / 1024 / 1024}MB limit`)
      return
    }

    // å¦‚æœæ²¡æœ‰ä¼šè®®ï¼Œå…ˆåˆ›å»ºä¸€ä¸ª
    if (!currentMeeting) {
      const meeting = await createMeeting(noteTitle)
      if (!meeting) return
      setCurrentMeeting(meeting)
    }

    // å¼€å§‹å¤„ç†æ–‡ä»¶
    setIsUploadingFile(true)
    setIsTranscribing(true)
    toast.info('Uploading audio file...')

    try {
      await handleTranscribeUploadedFile(file)
    } catch (error: any) {
      console.error('File upload error:', error)
      toast.error(error.message || 'Failed to upload and transcribe file')
      setIsUploadingFile(false)
      setIsTranscribing(false)
    } finally {
      // é‡ç½®æ–‡ä»¶è¾“å…¥
      if (fileInputRef.current) {
        fileInputRef.current.value = ''
      }
    }
  }, [currentMeeting, noteTitle])

  // ç”Ÿæˆæ‘˜è¦
  // useTemplate: æ˜¯å¦ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿ï¼ˆé»˜è®¤ trueï¼‰ï¼›false æ—¶ä½¿ç”¨ DeepSeek é»˜è®¤æç¤ºè¯ï¼ˆé€šç”¨ç»“æ„æ€»ç»“ï¼‰
  // language: æ‘˜è¦è¾“å‡ºè¯­è¨€ï¼ˆé»˜è®¤ 'en'ï¼‰
  const handleGenerateSummary = async (
    templateId?: string,
    contextPrompt?: string,
    language?: string,
    useTemplate: boolean = true
  ) => {
    if (!currentMeeting) {
      toast.error('No meeting found')
      return
    }

    try {
      const response = await fetch(`/api/meetings/${currentMeeting.id}/summary`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          template_id: templateId || 'default',
          context_prompt: contextPrompt,
          language: language || 'en',
          use_template: useTemplate,
        }),
      })

      if (!response.ok) throw new Error('Failed to generate summary')

      const { summary: newSummary } = await response.json()
      setSummary(newSummary)

      // è½®è¯¢æ‘˜è¦çŠ¶æ€ï¼ˆä½¿ç”¨ç”Ÿæˆæ—¶ä¼ å…¥çš„æ¨¡æ¿ IDï¼Œç¡®ä¿è½®è¯¢çš„æ˜¯æ­£ç¡®çš„æ¨¡æ¿ï¼‰
      const actualTemplateId = templateId || 'default'
      const pollSummary = async () => {
        const res = await fetch(`/api/meetings/${currentMeeting.id}/summary?template_id=${actualTemplateId}`)
        if (res.ok) {
          const { summary: s } = await res.json()
          // åªæœ‰å½“è½®è¯¢åˆ°çš„æ‘˜è¦å±äºå½“å‰è¯·æ±‚çš„æ¨¡æ¿æ—¶ï¼Œæ‰æ›´æ–°çŠ¶æ€
          // é¿å…è½®è¯¢åˆ°å…¶ä»–æ¨¡æ¿çš„æ‘˜è¦å¯¼è‡´ç•Œé¢è·³è½¬
          if (s && (!s.template_id || s.template_id === actualTemplateId)) {
            setSummary(s)
            if (s?.status === 'processing') {
              setTimeout(pollSummary, 2000)
            }
          } else if (!s) {
            // å¦‚æœè¿”å› nullï¼Œè¯´æ˜è¯¥æ¨¡æ¿è¿˜æ²¡æœ‰ç”Ÿæˆå®Œæˆï¼Œç»§ç»­è½®è¯¢
            setTimeout(pollSummary, 2000)
          }
        }
      }
      setTimeout(pollSummary, 2000)
    } catch (error: any) {
      toast.error(error.message || 'Failed to generate summary')
    }
  }

  // å¤„ç†ä¸Šä¼ æ–‡ä»¶çš„è½¬å½•
  const handleTranscribeUploadedFile = useCallback(async (audioFile: File) => {
    if (!currentMeeting) {
      throw new Error('No meeting found')
    }

    try {
      // è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆå¦‚æœå¯èƒ½ï¼‰
      let audioDuration: number | null = null
      try {
        const audio = new Audio()
        const url = URL.createObjectURL(audioFile)
        await new Promise<void>((resolve, reject) => {
          audio.onloadedmetadata = () => {
            audioDuration = audio.duration
            URL.revokeObjectURL(url)
            resolve()
          }
          audio.onerror = reject
          audio.src = url
        })
      } catch (e) {
        console.warn('Could not determine audio duration:', e)
      }

      // åˆ¤æ–­æ˜¯å¦éœ€è¦ä¸Šä¼ åˆ° Blob Storageï¼ˆå¤§äº 4MBï¼‰
      const MAX_INLINE_AUDIO_SIZE_MB = 4
      const audioSizeMB = audioFile.size / (1024 * 1024)
      
      // åˆ›å»ºç›´æ¥ä¸Šä¼ çš„ FormData è¾…åŠ©å‡½æ•°
      const createDirectUploadFormData = (): FormData => {
        const formData = new FormData()
        formData.append('audio', audioFile, audioFile.name)
        formData.append('language', transcriptionLanguage)
        formData.append('audioDuration', (audioDuration ?? 0).toString())
        return formData
      }
      
      let audioPayload: FormData | { audioUrl: string; audioDuration: string; language: string }

      if (audioSizeMB > MAX_INLINE_AUDIO_SIZE_MB) {
        console.log(`ğŸ“¤ Audio file size (${audioSizeMB.toFixed(2)} MB) exceeds ${MAX_INLINE_AUDIO_SIZE_MB} MB, attempting to upload to Blob Storage...`)
        const uploadFormData = new FormData()
        uploadFormData.append('file', audioFile, audioFile.name)
        
        try {
          const uploadResponse = await fetch('/api/upload', {
            method: 'POST',
            body: uploadFormData,
          })
          
          if (uploadResponse.ok) {
            const uploadData = await uploadResponse.json()
            
            // æ£€æŸ¥å“åº”æ ¼å¼
            if (uploadData.url && !uploadData.url.startsWith('data:')) {
              // æˆåŠŸä¸Šä¼ åˆ° Blob Storageï¼ˆä¸æ˜¯ base64 data URLï¼‰
              audioPayload = {
                audioUrl: uploadData.url,
                audioDuration: (audioDuration ?? 0).toString(),
                language: transcriptionLanguage
              }
              console.log('âœ… Audio uploaded to Blob Storage:', uploadData.url)
            } else {
              // base64 data URLï¼ˆBlob Storage æœªé…ç½®ï¼‰ï¼Œå›é€€åˆ°ç›´æ¥ä¸Šä¼ 
              console.warn('âš ï¸ Blob Storage not configured, received base64 data URL. Falling back to direct upload.')
              audioPayload = createDirectUploadFormData()
            }
          } else {
            // ä¸Šä¼ å¤±è´¥ï¼Œå›é€€åˆ°ç›´æ¥ä¸Šä¼ 
            const errorData = await uploadResponse.json().catch(() => ({}))
            console.warn('âš ï¸ Blob Storage upload failed, falling back to direct upload:', errorData.error || uploadResponse.statusText)
            audioPayload = createDirectUploadFormData()
          }
        } catch (uploadError: any) {
          // ä¸Šä¼ å¼‚å¸¸ï¼Œå›é€€åˆ°ç›´æ¥ä¸Šä¼ 
          console.warn('âš ï¸ Blob Storage upload error, falling back to direct upload:', uploadError.message)
          audioPayload = createDirectUploadFormData()
        }
      } else {
        // æ–‡ä»¶å°äºç­‰äº 4MBï¼Œç›´æ¥ä¸Šä¼ 
        console.log(`ğŸ“¤ Audio file size (${audioSizeMB.toFixed(2)} MB) is within limit, sending directly.`)
        audioPayload = createDirectUploadFormData()
      }

      // è°ƒç”¨è½¬å½• API
      const response = await fetch(`/api/meetings/${currentMeeting.id}/transcribe`, {
        method: 'POST',
        body: audioPayload instanceof FormData ? audioPayload : JSON.stringify(audioPayload),
        headers: audioPayload instanceof FormData ? {} : { 'Content-Type': 'application/json' },
      })

      if (!response.ok) {
        let errorMessage = 'Transcription failed'
        try {
          const errorData = await response.json()
          errorMessage = errorData.error || errorData.details || errorData.message || errorMessage
        } catch (e) {
          errorMessage = `Transcription failed (HTTP ${response.status})`
        }
        throw new Error(errorMessage)
      }

      const data = await response.json()
      const newTranscripts = data.transcripts || []
      const message = data.message || ''

      // æ£€æŸ¥æ˜¯å¦ä¸ºé™éŸ³æ£€æµ‹
      if (message === 'no recording detected') {
        setIsSilentDetected(true)
        toast.warning('No recording detected - audio appears to be silent')
        setSummary(null)
        setShowSummaryView(true)
        setIsUploadingFile(false)
        setIsTranscribing(false)
        return
      } else {
        setIsSilentDetected(false)
      }

      if (newTranscripts.length > 0) {
        setTranscripts(prev => [...prev, ...newTranscripts])
      }

      // æ›´æ–°ä¼šè®®çŠ¶æ€
      const updateResponse = await fetch(`/api/meetings/${currentMeeting.id}`, {
        method: 'PATCH',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          status: 'completed',
          audio_duration: audioDuration || 0
        })
      })

      if (updateResponse.ok) {
        const { meeting: updatedMeeting } = await updateResponse.json()
        setCurrentMeeting(updatedMeeting)
        if (showHistory) {
          loadHistoryMeetings()
        }
      }

      if (newTranscripts.length > 0) {
        toast.success('Transcription completed')
        setSummary(null)
        setShowSummaryView(true)

        // è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
        try {
          await handleGenerateSummary('default', undefined, 'en', false)
        } catch (e) {
          console.error('Auto-generate summary failed:', e)
        }
      } else {
        toast.warning('Transcription completed but no text was extracted')
        setSummary(null)
        setShowSummaryView(true)
      }

      setIsUploadingFile(false)
      setIsTranscribing(false)
    } catch (error: any) {
      console.error('Transcription error:', error)
      toast.error(error.message || 'Failed to transcribe audio file')
      setIsUploadingFile(false)
      setIsTranscribing(false)
      setSummary(null)
      setShowSummaryView(true)
    }
  }, [currentMeeting, transcriptionLanguage, showHistory, loadHistoryMeetings, handleGenerateSummary])

  // ä¿å­˜æ‘˜è¦ï¼ˆç°åœ¨ç”± AISummary ç»„ä»¶å†…éƒ¨å¤„ç†ï¼Œè¿™é‡Œä¿ç•™ä»¥ä¿æŒæ¥å£å…¼å®¹ï¼‰
  const handleSaveSummary = async (content: string) => {
    // è¿™ä¸ªå‡½æ•°ç°åœ¨ç”± AISummary ç»„ä»¶å†…éƒ¨å¤„ç†ï¼Œä¿ç•™ä»¥ä¿æŒæ¥å£å…¼å®¹
    // å®é™…ä¿å­˜é€»è¾‘åœ¨ AISummary ç»„ä»¶ä¸­
  }

  // ä¿å­˜æ ‡é¢˜
  const handleSaveTitle = async () => {
    setIsEditingTitle(false)
    if (currentMeeting && noteTitle.trim()) {
      try {
        await fetch(`/api/meetings/${currentMeeting.id}`, {
          method: 'PATCH',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ title: noteTitle })
        })
        toast.success('Title saved')
      } catch (error) {
        toast.error('Failed to save title')
      }
    }
  }

  // ç›‘å¬sidebarçš„å½•éŸ³äº‹ä»¶
  useEffect(() => {
    const handleRecordingToggle = (event: CustomEvent) => {
      if (event.detail.start && !isRecording) {
        startRecording()
      } else if (!event.detail.start && isRecording) {
        stopRecording()
      }
    }

    window.addEventListener('meeting-recording-toggle', handleRecordingToggle as EventListener)
    return () => {
      window.removeEventListener('meeting-recording-toggle', handleRecordingToggle as EventListener)
    }
  }, [isRecording, startRecording, stopRecording])

  // é€šçŸ¥sidebarå½•éŸ³çŠ¶æ€å˜åŒ–
  useEffect(() => {
    window.dispatchEvent(new CustomEvent('meeting-recording-state', {
      detail: { isRecording }
    }))
  }, [isRecording])

  // ç›‘å¬å†å²è§†å›¾åˆ‡æ¢
  useEffect(() => {
    const handleHistoryToggle = (event: CustomEvent) => {
      const shouldShow = event.detail.show
      setShowHistory(shouldShow)
      if (shouldShow) {
        loadHistoryMeetings()
      }
    }

    window.addEventListener('meeting-history-toggle', handleHistoryToggle as EventListener)
    return () => {
      window.removeEventListener('meeting-history-toggle', handleHistoryToggle as EventListener)
    }
  }, [loadHistoryMeetings])

  // åŒæ­¥ä¼šè®®IDåˆ°refï¼ˆç¡®ä¿å®šæ—¶å™¨å¯ä»¥è®¿é—®æœ€æ–°çš„ä¼šè®®IDï¼‰
  useEffect(() => {
    currentMeetingIdRef.current = currentMeeting?.id || null
  }, [currentMeeting?.id])

  // åŠ è½½ä¼šè®®æ•°æ®
  useEffect(() => {
    if (currentMeeting?.id) {
      loadMeetingData(currentMeeting.id)
    }
  }, [currentMeeting?.id])

  // åŠ è½½è¯­è¨€åå¥½
  useEffect(() => {
    const saved = getLanguagePreference()
    setTranscriptionLanguage(saved)
    transcriptionLanguageRef.current = saved
  }, [])

  // æ›´æ–°è¯­è¨€åå¥½ ref
  useEffect(() => {
    transcriptionLanguageRef.current = transcriptionLanguage
  }, [transcriptionLanguage])

  // æ¸…ç†
  useEffect(() => {
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current)
      }
      if (transcriptionIntervalRef.current) {
        clearInterval(transcriptionIntervalRef.current)
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop())
      }
      if (audioContextRef.current) {
        audioContextRef.current.close()
      }
    }
  }, [])

  // å½•éŸ³é¡µé¢è§†å›¾
  const renderRecordingView = () => (
    <div className="flex flex-col h-full max-w-4xl mx-auto w-full">
      {/* é¡¶éƒ¨æ ‡é¢˜æ  */}
      <div className="flex items-center justify-between p-4 border-b bg-white">
        <div className="flex items-center gap-4">
          {/* è¯­è¨€é€‰æ‹© */}
          <LanguageSelection 
            onLanguageChange={(lang) => setTranscriptionLanguage(lang)}
          />
          
          {isEditingTitle ? (
            <div className="flex items-center gap-2">
              <Input
                value={noteTitle}
                onChange={(e) => setNoteTitle(e.target.value)}
                onBlur={handleSaveTitle}
                onKeyDown={(e) => {
                  if (e.key === 'Enter') {
                    handleSaveTitle()
                  }
                }}
                className="text-xl font-semibold border-0 border-b-2 border-gray-300 focus:border-primary rounded-none px-0"
                autoFocus
              />
              <Button
                variant="ghost"
                size="icon"
                onClick={handleSaveTitle}
                className="h-6 w-6"
              >
                <Save className="w-4 h-4" />
              </Button>
            </div>
          ) : (
            <div className="flex items-center gap-2 group">
              <h2 
                className="text-xl font-semibold text-gray-700 cursor-pointer hover:text-gray-900 transition-colors"
                onClick={() => setIsEditingTitle(true)}
              >
                {noteTitle}
              </h2>
              <Button
                variant="ghost"
                size="icon"
                onClick={() => setIsEditingTitle(true)}
                className="h-6 w-6 opacity-0 group-hover:opacity-100 transition-opacity"
              >
                <Edit2 className="w-4 h-4" />
              </Button>
            </div>
          )}
        </div>
      </div>

      {/* å½•éŸ³æ—¶çš„è½¬å½•æ–‡æœ¬æ˜¾ç¤ºï¼ˆæ”¯æŒæ‰‹åŠ¨è®°å½•ï¼‰ */}
      {isRecording && (
        <div className="flex-1 overflow-hidden bg-white rounded-lg shadow-sm mx-4 my-2">
          <TranscriptView
            meetingId={currentMeeting?.id || ''}
            transcripts={transcripts}
            manualNotes={manualNotes}
            isTranscribing={false}
            isRecording={isRecording}
            recordingTime={recordingTime}
            onManualNoteAdd={(note) => setManualNotes(prev => [...prev, note])}
          />
        </div>
      )}

      {/* å½•éŸ³æ§åˆ¶åŒºåŸŸ - ä»…åœ¨å½•éŸ³æ—¶æ˜¾ç¤ºåœ¨åº•éƒ¨ */}
      {isRecording && (
        <div className="border-t border-gray-200 pt-6 mt-auto">
          <div className="flex items-center justify-center gap-6">
            {/* æš‚åœæŒ‰é’® */}
            <Button
              onClick={togglePause}
              variant="outline"
              size="lg"
              className="rounded-xl bg-gray-50 hover:bg-gray-100 border-gray-200 shadow-sm h-12 w-12 p-0"
            >
              {isPaused ? (
                <Play className="w-5 h-5 text-gray-700" />
              ) : (
                <Pause className="w-5 h-5 text-gray-700" />
              )}
            </Button>

            {/* éŸ³é¢‘å¯è§†åŒ–å™¨å’Œæ—¶é—´ */}
            <div className="flex items-center gap-3">
              {/* éŸ³é¢‘å¯è§†åŒ–å™¨ */}
              <div className="flex items-end gap-1 h-10">
                {audioLevels.length > 0 ? (
                  audioLevels.map((level, index) => (
                    <div
                      key={index}
                      className="w-1.5 bg-blue-500 rounded-t transition-all duration-75"
                      style={{
                        height: `${Math.max(20, level * 100)}%`,
                        minHeight: '4px'
                      }}
                    />
                  ))
                ) : (
                  Array.from({ length: 12 }).map((_, index) => (
                    <div
                      key={index}
                      className="w-1.5 bg-blue-200 rounded-t"
                      style={{
                        height: '20%',
                        minHeight: '4px'
                      }}
                    />
                  ))
                )}
              </div>

              {/* å½•éŸ³æ—¶é—´å’ŒçŠ¶æ€ */}
              <div className="flex items-center gap-2">
                <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse" />
                <span className="text-blue-600 font-semibold text-lg">
                  {formatTime(recordingTime)}
                </span>
              </div>
            </div>

            {/* ç»“æŸæŒ‰é’® */}
            <Button
              onClick={stopRecording}
              size="lg"
              className="rounded-xl bg-red-500 hover:bg-red-600 text-white px-6 h-12 shadow-sm font-medium"
            >
              End
            </Button>
          </div>
        </div>
      )}

      {/* å½•éŸ³å‰ï¼šå¼€å§‹å½•éŸ³æŒ‰é’®å’Œä¸Šä¼ æ–‡ä»¶æŒ‰é’® - åœ¨æœ€ä¸‹é¢ä¸­é—´ */}
      {!isRecording && transcripts.length === 0 && (
        <div className="mt-auto pt-8 pb-12">
          <div className="flex flex-col items-center gap-4">
            {/* å¼€å§‹å½•éŸ³æŒ‰é’® */}
            <Button
              onClick={startRecording}
              size="lg"
              className="rounded-full w-20 h-20 bg-red-500 hover:bg-red-600 shadow-lg"
            >
              <Mic className="w-10 h-10 text-white" />
            </Button>
            
            {/* åˆ†éš”çº¿ */}
            <div className="flex items-center gap-3 w-full max-w-xs">
              <div className="flex-1 h-px bg-gray-300"></div>
              <span className="text-sm text-gray-500">or</span>
              <div className="flex-1 h-px bg-gray-300"></div>
            </div>
            
            {/* ä¸Šä¼ æ–‡ä»¶æŒ‰é’® */}
            <div className="flex flex-col items-center gap-2">
              <Button
                onClick={() => fileInputRef.current?.click()}
                disabled={isUploadingFile || isTranscribing}
                size="lg"
                variant="outline"
                className="rounded-xl px-6 h-12 border-2 border-dashed border-gray-300 hover:border-blue-500 hover:bg-blue-50 transition-colors"
              >
                {isUploadingFile || isTranscribing ? (
                  <>
                    <div className="w-4 h-4 border-2 border-blue-500 border-t-transparent rounded-full animate-spin mr-2" />
                    Processing...
                  </>
                ) : (
                  <>
                    <Upload className="w-5 h-5 mr-2" />
                    Upload Audio File
                  </>
                )}
              </Button>
              <p className="text-xs text-gray-500 text-center max-w-xs">
                Support WAV, MP3, M4A, OGG, WEBM, AAC (max 100MB)
              </p>
            </div>
            
            {/* éšè—çš„æ–‡ä»¶è¾“å…¥ */}
            <input
              ref={fileInputRef}
              type="file"
              accept="audio/*,.wav,.mp3,.m4a,.ogg,.webm,.aac"
              onChange={handleFileUpload}
              className="hidden"
            />
          </div>
        </div>
      )}
    </div>
  )

  // åŒæ å¸ƒå±€è§†å›¾ï¼ˆåœæ­¢å½•åˆ¶åæ˜¾ç¤ºï¼‰
  const renderSummaryView = () => (
    <div className="flex flex-col h-full">
      {/* é¡¶éƒ¨æ ‡é¢˜æ  */}
      <div className="flex items-center justify-between p-4 border-b bg-white">
        <div className="flex items-center gap-4">
          {/* è¯­è¨€é€‰æ‹© */}
          <LanguageSelection 
            onLanguageChange={(lang) => setTranscriptionLanguage(lang)}
          />
          
          {isEditingTitle ? (
            <div className="flex items-center gap-2">
              <Input
                value={noteTitle}
                onChange={(e) => setNoteTitle(e.target.value)}
                onBlur={handleSaveTitle}
                onKeyDown={(e) => {
                  if (e.key === 'Enter') {
                    handleSaveTitle()
                  }
                }}
                className="text-xl font-semibold border-0 border-b-2 border-gray-300 focus:border-primary rounded-none px-0"
                autoFocus
              />
              <Button
                variant="ghost"
                size="icon"
                onClick={handleSaveTitle}
                className="h-6 w-6"
              >
                <Save className="w-4 h-4" />
              </Button>
            </div>
          ) : (
            <div className="flex items-center gap-2 group">
              <h2 
                className="text-xl font-semibold text-gray-700 cursor-pointer hover:text-gray-900 transition-colors"
                onClick={() => setIsEditingTitle(true)}
              >
                {noteTitle}
              </h2>
              <Button
                variant="ghost"
                size="icon"
                onClick={() => setIsEditingTitle(true)}
                className="h-6 w-6 opacity-0 group-hover:opacity-100 transition-opacity"
              >
                <Edit2 className="w-4 h-4" />
              </Button>
            </div>
          )}
        </div>

        <Button
          onClick={() => {
            setShowSummaryView(false)
            setTranscripts([])
            setSummary(null)
            setCurrentMeeting(null)
            setNoteTitle('New Note')
            setManualNotes([]) // æ¸…é™¤ä¹‹å‰çš„ user highlights
            setShowHistory(false)
            // é€šçŸ¥sidebarå…³é—­å†å²è§†å›¾
            window.dispatchEvent(new CustomEvent('meeting-history-toggle', {
              detail: { show: false }
            }))
          }}
          size="sm"
          variant="outline"
          className="rounded-lg"
        >
          <Mic className="w-4 h-4 mr-2" />
          New Recording
        </Button>
      </div>

      {/* åŒæ å¸ƒå±€ */}
      <div className="flex-1 flex overflow-hidden">
        {/* å·¦ä¾§ï¼šè½¬å½•æ–‡æœ¬ */}
        <div className="w-1/2 border-r bg-white">
          <TranscriptView
            meetingId={currentMeeting?.id || ''}
            transcripts={transcripts}
            manualNotes={manualNotes}
            isTranscribing={isTranscribing}
            isRecording={isRecording}
            recordingTime={recordingTime}
            onManualNoteAdd={(note) => setManualNotes(prev => [...prev, note])}
          />
        </div>

        {/* å³ä¾§ï¼šAI æ€»ç»“ */}
        <div className="w-1/2 bg-white">
          <AISummary
            meetingId={currentMeeting?.id || ''}
            summary={summary}
            onGenerate={handleGenerateSummary}
            onSave={handleSaveSummary}
            isRecording={false}
          />
        </div>
      </div>
    </div>
  )

  // å†å²è®°å½•è§†å›¾
  const renderHistoryView = () => (
    <div className="flex flex-col h-full max-w-4xl mx-auto w-full">
      {/* é¡¶éƒ¨æ ‡é¢˜æ  */}
      <div className="flex items-center justify-between p-4 border-b bg-white">
        <div className="flex items-center gap-2">
          <History className="w-5 h-5 text-gray-600" />
          <h2 className="text-xl font-semibold text-gray-700">Meeting History</h2>
        </div>
        <Button
          variant="ghost"
          size="sm"
          onClick={() => {
            setShowHistory(false)
            window.dispatchEvent(new CustomEvent('meeting-history-toggle', {
              detail: { show: false }
            }))
          }}
        >
          Close
        </Button>
      </div>

      {/* å†å²è®°å½•åˆ—è¡¨ */}
      <div className="flex-1 overflow-auto p-6">
        {isLoadingHistory ? (
          <div className="flex items-center justify-center h-full">
            <p className="text-gray-400">Loading history...</p>
          </div>
        ) : historyMeetings.length === 0 ? (
          <div className="flex flex-col items-center justify-center h-full text-gray-400">
            <History className="w-16 h-16 mb-4 opacity-50" />
            <p className="text-lg">No meeting history</p>
            <p className="text-sm mt-2">Your completed meetings will appear here</p>
          </div>
        ) : (
          <div className="space-y-3">
            {historyMeetings.map((meeting) => (
              <div
                key={meeting.id}
                onClick={() => {
                  if (editingMeetingId !== meeting.id) {
                    loadMeeting(meeting.id)
                  }
                }}
                className="p-4 border border-gray-200 rounded-lg hover:border-blue-300 hover:shadow-md transition-all cursor-pointer bg-white"
              >
                <div className="flex items-start justify-between gap-4">
                  {/* å·¦ä¾§ï¼šå›¾æ ‡å’Œå†…å®¹ */}
                  <div className="flex items-start gap-3 flex-1 min-w-0">
                    <div className="flex-shrink-0 w-10 h-10 rounded-full bg-gray-100 flex items-center justify-center">
                      <FileText className="w-5 h-5 text-gray-500" />
                    </div>
                    <div className="flex-1 min-w-0">
                      {editingMeetingId === meeting.id ? (
                        <Input
                          value={editingTitle}
                          onChange={(e) => setEditingTitle(e.target.value)}
                          onKeyDown={(e) => {
                            if (e.key === 'Enter') {
                              saveMeetingTitle(meeting.id, e)
                            } else if (e.key === 'Escape') {
                              cancelEditing(e)
                            }
                          }}
                          onClick={(e) => e.stopPropagation()}
                          onBlur={() => {
                            if (editingTitle.trim() && editingTitle !== meeting.title) {
                              saveMeetingTitle(meeting.id)
                            } else {
                              cancelEditing()
                            }
                          }}
                          className="font-semibold text-gray-800 mb-2"
                          autoFocus
                        />
                      ) : (
                        <h3 className="font-semibold text-gray-800 truncate mb-2">
                          {meeting.title}
                        </h3>
                      )}
                      <div className="flex items-center gap-4 text-sm text-gray-500">
                        <span>
                          {new Date(meeting.created_at).toLocaleString()}
                        </span>
                        {meeting.audio_duration && (
                          <span>
                            Duration: {formatTime(meeting.audio_duration)}
                          </span>
                        )}
                      </div>
                    </div>
                  </div>

                  {/* å³ä¾§ï¼šæ“ä½œæŒ‰é’® */}
                  <div className="flex items-center gap-2 flex-shrink-0">
                    {editingMeetingId === meeting.id ? (
                      <Button
                        variant="ghost"
                        size="icon"
                        onClick={(e) => saveMeetingTitle(meeting.id, e)}
                        className="h-8 w-8 text-blue-600 hover:text-blue-700 hover:bg-blue-50"
                      >
                        <Save className="w-4 h-4" />
                      </Button>
                    ) : (
                      <>
                        <Button
                          variant="ghost"
                          size="icon"
                          onClick={(e) => startEditingTitle(meeting, e)}
                          className="h-8 w-8 text-gray-600 hover:text-gray-700 hover:bg-gray-50"
                        >
                          <Edit2 className="w-4 h-4" />
                        </Button>
                        <Button
                          variant="ghost"
                          size="icon"
                          onClick={(e) => deleteMeeting(meeting.id, e)}
                          className="h-8 w-8 text-red-600 hover:text-red-700 hover:bg-red-50"
                        >
                          <Trash2 className="w-4 h-4" />
                        </Button>
                      </>
                    )}
                  </div>
                </div>
              </div>
            ))}
          </div>
        )}
      </div>
    </div>
  )

  // æ ¹æ®è§†å›¾çŠ¶æ€æ¸²æŸ“
  if (showHistory) {
    return renderHistoryView()
  }

  return showSummaryView ? renderSummaryView() : renderRecordingView()
}

